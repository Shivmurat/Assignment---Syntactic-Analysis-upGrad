{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pprint, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#checking some tagged data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Mr.', 'NOUN'), ('Vinken', 'NOUN'), ('is', 'VERB'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Elsevier', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('the', 'DET'), ('Dutch', 'NOUN'), ('publishing', 'VERB'), ('group', 'NOUN'), ('.', '.')], [('Rudolph', 'NOUN'), ('Agnew', 'NOUN'), (',', '.'), ('55', 'NUM'), ('years', 'NOUN'), ('old', 'ADJ'), ('and', 'CONJ'), ('former', 'ADJ'), ('chairman', 'NOUN'), ('of', 'ADP'), ('Consolidated', 'NOUN'), ('Gold', 'NOUN'), ('Fields', 'NOUN'), ('PLC', 'NOUN'), (',', '.'), ('was', 'VERB'), ('named', 'VERB'), ('*-1', 'X'), ('a', 'DET'), ('nonexecutive', 'ADJ'), ('director', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('British', 'ADJ'), ('industrial', 'ADJ'), ('conglomerate', 'NOUN'), ('.', '.')], [('A', 'DET'), ('form', 'NOUN'), ('of', 'ADP'), ('asbestos', 'NOUN'), ('once', 'ADV'), ('used', 'VERB'), ('*', 'X'), ('*', 'X'), ('to', 'PRT'), ('make', 'VERB'), ('Kent', 'NOUN'), ('cigarette', 'NOUN'), ('filters', 'NOUN'), ('has', 'VERB'), ('caused', 'VERB'), ('a', 'DET'), ('high', 'ADJ'), ('percentage', 'NOUN'), ('of', 'ADP'), ('cancer', 'NOUN'), ('deaths', 'NOUN'), ('among', 'ADP'), ('a', 'DET'), ('group', 'NOUN'), ('of', 'ADP'), ('workers', 'NOUN'), ('exposed', 'VERB'), ('*', 'X'), ('to', 'PRT'), ('it', 'PRON'), ('more', 'ADV'), ('than', 'ADP'), ('30', 'NUM'), ('years', 'NOUN'), ('ago', 'ADP'), (',', '.'), ('researchers', 'NOUN'), ('reported', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('.', '.')], [('The', 'DET'), ('asbestos', 'NOUN'), ('fiber', 'NOUN'), (',', '.'), ('crocidolite', 'NOUN'), (',', '.'), ('is', 'VERB'), ('unusually', 'ADV'), ('resilient', 'ADJ'), ('once', 'ADP'), ('it', 'PRON'), ('enters', 'VERB'), ('the', 'DET'), ('lungs', 'NOUN'), (',', '.'), ('with', 'ADP'), ('even', 'ADV'), ('brief', 'ADJ'), ('exposures', 'NOUN'), ('to', 'PRT'), ('it', 'PRON'), ('causing', 'VERB'), ('symptoms', 'NOUN'), ('that', 'DET'), ('*T*-1', 'X'), ('show', 'VERB'), ('up', 'PRT'), ('decades', 'NOUN'), ('later', 'ADJ'), (',', '.'), ('researchers', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-2', 'X'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "print(nltk_data[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#As per instruction Splitting the dataset in sample size of 95:5 for training: validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set,test_set = train_test_split(nltk_data,train_size=0.95,test_size=0.05,random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95547\n",
      "5129\n"
     ]
    }
   ],
   "source": [
    "# create list of train and test tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "test_tagged_words = [tup for sent in test_set for tup in sent]\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('confirmed', 'VERB'), ('the', 'DET'), ('filing', 'NOUN'), ('but', 'CONJ')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some of the train tagged words.\n",
    "train_tagged_words[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('company', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('it', 'PRON')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some of the test tagged words.\n",
    "test_tagged_words[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'DET', 'ADJ', 'NUM', 'CONJ', 'VERB', '.', 'PRON', 'NOUN', 'X', 'ADV', 'PRT', 'ADP'}\n"
     ]
    }
   ],
   "source": [
    "# checking unique tags present in training data\n",
    "tags = {tag for word,tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12100\n"
     ]
    }
   ],
   "source": [
    "# let's check how many words are present in vocabulary\n",
    "vocab = {word for word,tag in train_tagged_words}\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compute emission probablity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emission probablity function\n",
    "def word_given_tag(word,tag,train_bag= train_tagged_words):\n",
    "    taglist = [pair for pair in train_bag if pair[1] == tag]\n",
    "    tag_count = len(taglist)    \n",
    "    w_in_tag = [pair[0] for pair in taglist if pair[0]==word]    \n",
    "    word_count_given_tag = len(w_in_tag)    \n",
    "    \n",
    "    return (word_count_given_tag,tag_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compute transition probabilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute transition probabilities of a previous and next tag\n",
    "def t2_given_t1(t2,t1,train_bag=train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    \n",
    "    t1_tags = [tag for tag in tags if tag==t1]\n",
    "    \n",
    "    count_of_t1 = len(t1_tags)\n",
    "    \n",
    "    t2_given_t1 = [tags[index+1] for index in range(len(tags)-1) if tags[index] == t1 and tags[index+1] == t2]\n",
    "    \n",
    "    count_t2_given_t1 = len(t2_given_t1)\n",
    "    \n",
    "    return(count_t2_given_t1,count_of_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5284, 8281)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_given_t1('NOUN','DET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 6069)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2_given_t1('VERB','ADJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "\n",
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DET</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>NUM</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>.</th>\n",
       "      <th>PRON</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>X</th>\n",
       "      <th>ADV</th>\n",
       "      <th>PRT</th>\n",
       "      <th>ADP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.005676</td>\n",
       "      <td>0.204323</td>\n",
       "      <td>0.022220</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.039850</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.003744</td>\n",
       "      <td>0.638087</td>\n",
       "      <td>0.045405</td>\n",
       "      <td>0.012438</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.009540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.004943</td>\n",
       "      <td>0.066403</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.016971</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.063931</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.699621</td>\n",
       "      <td>0.021091</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.010710</td>\n",
       "      <td>0.078267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.184932</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>0.018761</td>\n",
       "      <td>0.117332</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.350208</td>\n",
       "      <td>0.210542</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.026504</td>\n",
       "      <td>0.036033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.121339</td>\n",
       "      <td>0.118085</td>\n",
       "      <td>0.039981</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.156671</td>\n",
       "      <td>0.034868</td>\n",
       "      <td>0.058113</td>\n",
       "      <td>0.349140</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.055323</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.052534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.134392</td>\n",
       "      <td>0.064988</td>\n",
       "      <td>0.022851</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.169249</td>\n",
       "      <td>0.034934</td>\n",
       "      <td>0.035786</td>\n",
       "      <td>0.110070</td>\n",
       "      <td>0.217506</td>\n",
       "      <td>0.081952</td>\n",
       "      <td>0.030674</td>\n",
       "      <td>0.092022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.173335</td>\n",
       "      <td>0.043963</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.057538</td>\n",
       "      <td>0.089095</td>\n",
       "      <td>0.093320</td>\n",
       "      <td>0.066349</td>\n",
       "      <td>0.222242</td>\n",
       "      <td>0.026971</td>\n",
       "      <td>0.052324</td>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.091342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.009954</td>\n",
       "      <td>0.073124</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>0.485452</td>\n",
       "      <td>0.040965</td>\n",
       "      <td>0.007657</td>\n",
       "      <td>0.210949</td>\n",
       "      <td>0.089969</td>\n",
       "      <td>0.034074</td>\n",
       "      <td>0.013017</td>\n",
       "      <td>0.022971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.012942</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>0.042666</td>\n",
       "      <td>0.147667</td>\n",
       "      <td>0.240604</td>\n",
       "      <td>0.004607</td>\n",
       "      <td>0.263564</td>\n",
       "      <td>0.029175</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.043397</td>\n",
       "      <td>0.176514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.054742</td>\n",
       "      <td>0.017187</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>0.010662</td>\n",
       "      <td>0.203851</td>\n",
       "      <td>0.163590</td>\n",
       "      <td>0.055538</td>\n",
       "      <td>0.062381</td>\n",
       "      <td>0.076384</td>\n",
       "      <td>0.024984</td>\n",
       "      <td>0.185232</td>\n",
       "      <td>0.142584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.069891</td>\n",
       "      <td>0.129182</td>\n",
       "      <td>0.030474</td>\n",
       "      <td>0.006956</td>\n",
       "      <td>0.343491</td>\n",
       "      <td>0.137131</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>0.031467</td>\n",
       "      <td>0.023186</td>\n",
       "      <td>0.080490</td>\n",
       "      <td>0.014243</td>\n",
       "      <td>0.118582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.097858</td>\n",
       "      <td>0.083031</td>\n",
       "      <td>0.056672</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.405272</td>\n",
       "      <td>0.043822</td>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.247776</td>\n",
       "      <td>0.013509</td>\n",
       "      <td>0.010214</td>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.020099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.324709</td>\n",
       "      <td>0.107024</td>\n",
       "      <td>0.062226</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.008340</td>\n",
       "      <td>0.039025</td>\n",
       "      <td>0.070031</td>\n",
       "      <td>0.320967</td>\n",
       "      <td>0.034427</td>\n",
       "      <td>0.014006</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.016893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DET       ADJ       NUM      CONJ      VERB         .      PRON  \\\n",
       "DET   0.005676  0.204323  0.022220  0.000483  0.039850  0.017993  0.003744   \n",
       "ADJ   0.004943  0.066403  0.021256  0.016971  0.011699  0.063931  0.000330   \n",
       "NUM   0.003276  0.034247  0.184932  0.013699  0.018761  0.117332  0.001489   \n",
       "CONJ  0.121339  0.118085  0.039981  0.000465  0.156671  0.034868  0.058113   \n",
       "VERB  0.134392  0.064988  0.022851  0.005577  0.169249  0.034934  0.035786   \n",
       ".     0.173335  0.043963  0.081003  0.057538  0.089095  0.093320  0.066349   \n",
       "PRON  0.009954  0.073124  0.006508  0.005360  0.485452  0.040965  0.007657   \n",
       "NOUN  0.012942  0.012248  0.009542  0.042666  0.147667  0.240604  0.004607   \n",
       "X     0.054742  0.017187  0.002864  0.010662  0.203851  0.163590  0.055538   \n",
       "ADV   0.069891  0.129182  0.030474  0.006956  0.343491  0.137131  0.014906   \n",
       "PRT   0.097858  0.083031  0.056672  0.002306  0.405272  0.043822  0.017792   \n",
       "ADP   0.324709  0.107024  0.062226  0.000962  0.008340  0.039025  0.070031   \n",
       "\n",
       "          NOUN         X       ADV       PRT       ADP  \n",
       "DET   0.638087  0.045405  0.012438  0.000242  0.009540  \n",
       "ADJ   0.699621  0.021091  0.004778  0.010710  0.078267  \n",
       "NUM   0.350208  0.210542  0.002978  0.026504  0.036033  \n",
       "CONJ  0.349140  0.008833  0.055323  0.004649  0.052534  \n",
       "VERB  0.110070  0.217506  0.081952  0.030674  0.092022  \n",
       ".     0.222242  0.026971  0.052324  0.002427  0.091342  \n",
       "PRON  0.210949  0.089969  0.034074  0.013017  0.022971  \n",
       "NOUN  0.263564  0.029175  0.017074  0.043397  0.176514  \n",
       "X     0.062381  0.076384  0.024984  0.185232  0.142584  \n",
       "ADV   0.031467  0.023186  0.080490  0.014243  0.118582  \n",
       "PRT   0.247776  0.013509  0.010214  0.001647  0.020099  \n",
       "ADP   0.320967  0.034427  0.014006  0.001390  0.016893  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viterbi Algorithm steps\n",
    "\n",
    "1. Given a sequence of words.\n",
    "2. iterate through the sequence.\n",
    "3. for each word (starting from first word in sequence) calculate the product of emission probabilties and transition probabilties for all possible tags.\n",
    "4. assign the tag which has maximum probability obtained in step 3 above.\n",
    "5. move to the next word in sequence to repeat steps 3 and 4 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla Viterbi Algorithm\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    \n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "\n",
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(5)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  21.82012701034546\n",
      "Vanilla Viterbi Algorithm Accuracy:  89.38053097345133\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "\n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Vanilla Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Contra', 'DET'), ('Contra', 'NOUN')),\n",
       " (('command', 'VERB'), ('command', 'NOUN')),\n",
       " (('Honduras', 'DET'), ('Honduras', 'NOUN')),\n",
       " (('Sandinista', 'DET'), ('Sandinista', 'NOUN')),\n",
       " (('offensive', 'DET'), ('offensive', 'NOUN')),\n",
       " (('rebel', 'DET'), ('rebel', 'NOUN')),\n",
       " (('Bucking', 'DET'), ('Bucking', 'VERB')),\n",
       " (('drew', 'DET'), ('drew', 'VERB')),\n",
       " (('Eveready', 'DET'), ('Eveready', 'NOUN')),\n",
       " (('*T*-252', 'DET'), ('*T*-252', 'X')),\n",
       " (('complaining', 'DET'), ('complaining', 'VERB')),\n",
       " (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all of unknown words have been tagged as 'NUM', as 'NUM' is the first tag in tag list and is assigned if unknown word is encountered (emission probability =0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Modification-Technique I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use transition probability of tags when emission probability is zero (in case of unknown words)\n",
    "\n",
    "def Viterbi_1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "      \n",
    "        # if probability is zero (unknown word) then use transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]\n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  17.674171924591064\n",
      "Modified Viterbi_1 Accuracy:  94.69026548672566\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_1(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi_1 Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Tag occurance probability weights: \n",
    "Applying weights based on the probability of tag occurance to the transition probabilities of tags and then use the resulting probability for predicting unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DET', 0.08666938784053921),\n",
       " ('ADJ', 0.06351847781719991),\n",
       " ('NUM', 0.035145007169246546),\n",
       " ('CONJ', 0.02251248076862696),\n",
       " ('VERB', 0.1351167488251855),\n",
       " ('.', 0.11641391147812072),\n",
       " ('PRON', 0.0273373313657153),\n",
       " ('NOUN', 0.2862674913916711),\n",
       " ('X', 0.06576867928872701),\n",
       " ('ADV', 0.031597015081582885),\n",
       " ('PRT', 0.03176447193527793),\n",
       " ('ADP', 0.0978889970381069)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating list containing tuples of POS tags and POS tag occurance probability, based on training data\n",
    "tag_prob = []\n",
    "total_tag = len([tag for word,tag in train_tagged_words])\n",
    "for t in tags:\n",
    "    each_tag = [tag for word,tag in train_tagged_words if tag==t]\n",
    "    tag_prob.append((t,len(each_tag)/total_tag))\n",
    "\n",
    "tag_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_1(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # list for storing transition probabilities\n",
    "       \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            \n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            transition_p = tag_p[0]*transition_p             \n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = T[p.index(pmax)] \n",
    "        \n",
    "      \n",
    "        # if probability is zero (unknown word) then use weighted transition probability\n",
    "        if(pmax==0):\n",
    "            pmax = max(p_transition)\n",
    "            state_max = T[p_transition.index(pmax)]                 \n",
    "                           \n",
    "        else:\n",
    "            state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  21.056157112121582\n",
      "Modified Viterbi_1 Accuracy:  95.57522123893806\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_1(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi_1 Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see accuracy is improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('command', 'VERB'), ('command', 'NOUN')),\n",
       " (('Sandinista', 'VERB'), ('Sandinista', 'NOUN')),\n",
       " (('Eveready', 'VERB'), ('Eveready', 'NOUN')),\n",
       " (('*T*-252', 'VERB'), ('*T*-252', 'X')),\n",
       " (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### we can see words have been correctly POS tagged by Viterbi_1 as compared to vanilla Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viterbi Modification-Technique II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we further observe that POS tag 'X' can be easily encapsulated in regex rule, so we extract it only based on ruled based tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'.*', 'NOUN')                   # nouns\n",
    "]\n",
    "\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification in Viterbi Algorithm : Backoff to rule based tagger in case unknown word is encountered.\n",
    "def Viterbi_2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1]       \n",
    "       \n",
    "        \n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
    "        else:\n",
    "            if state_max != 'X':\n",
    "                # getting state for which probability is maximum\n",
    "                state_max = T[p.index(pmax)]                \n",
    "            \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  21.067126035690308\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Viterbi_2 Accuracy:  97.34513274336283\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi_2 Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('command', 'VERB'), ('command', 'NOUN')),\n",
       " (('drew', 'NOUN'), ('drew', 'VERB')),\n",
       " (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of words have been correctly POS tagged by Viterbi_2 as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "Contra:correctly tagged as NOUN\n",
    "Honduras:correctly tagged as NOUN\n",
    "complaining: correctly tagged as VERB\n",
    "Bucking: correctly tagged as VERB\n",
    "the following list of words has been correctly tagged by Viterbi_2 as compared to Viterbi_1\n",
    "\n",
    "Sandinista: correctly tagged as NOUN\n",
    "Eveready: correctly tagged as NOUN\n",
    "*T*-252: correctly tagged as 'X'\n",
    "#### further modification in Viterb_2: \n",
    "We know that the rule based tagger assigns 'NOUN' by default if word does not fall in any rule, to correct this let's assign the tags for any such word based purely on transition probability of tags.\n",
    "\n",
    "So, first we will modify the rule based tagger to output 'NN' instead of 'NOUN' in case word does not satisfy any rules. We also observe that any capitalized word can still be defaulted as 'NOUN' so will add one more rule for that case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense \n",
    "    (r'.*es$', 'VERB'),               # verb    \n",
    "    (r'.*\\'s$', 'NOUN'),              # possessive nouns\n",
    "    (r'.*s$', 'NOUN'),                # plural nouns\n",
    "    (r'\\*T?\\*?-[0-9]+$', 'X'),        # X\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'^[A-Z][a-z].*', 'NOUN'),       # NOUN\n",
    "    (r'.*', 'NN')                     # default\n",
    "]\n",
    "\n",
    "# rule based tagger\n",
    "rule_based_tagger = nltk.RegexpTagger(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified Viterbi\n",
    "def Viterbi_2(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        p_transition =[] # for storing transition probabilities\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "            # find POS tag occurance probability\n",
    "            tag_p = [pair[1] for pair in tag_prob if pair[0]==tag ]\n",
    "            \n",
    "            # calculate the transition prob weighted by tag occurance probability.\n",
    "            transition_p = tag_p[0]*transition_p\n",
    "            p_transition.append(transition_p)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        state_max = rule_based_tagger.tag([word])[0][1] \n",
    "        \n",
    "      \n",
    "        # getting state for which probability is maximum\n",
    "        if(pmax==0):\n",
    "            state_max = rule_based_tagger.tag([word])[0][1] # assign based on rule based tagger\n",
    "            \n",
    "            # if unknown word does not satisfy any rule, find the tag with maximum transition probability\n",
    "            if state_max == 'NN':\n",
    "                pmax = max(p_transition)\n",
    "                state_max = T[p_transition.index(pmax)]                 \n",
    "                \n",
    "        else:\n",
    "             if state_max != 'X':\n",
    "                # getting state for which probability is maximum\n",
    "                state_max = T[p.index(pmax)] \n",
    "        \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  18.668055772781372\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Viterbi Algorithm Accuracy:  98.23008849557522\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see accurency is improved significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('command', 'VERB'), ('command', 'NOUN')), (('up', 'ADV'), ('up', 'PRT'))]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check the incorrectly tagged words\n",
    "[j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0] != j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following list of words have been correctly POS tagged by Viterbi_2 as compared to vanilla Viterbi Algorithm:\n",
    "\n",
    "* Contra:correctly tagged as NOUN\n",
    "* Honduras:correctly tagged as NOUN\n",
    "* complaining: correctly tagged as VERB\n",
    "* Bucking: correctly tagged as VERB\n",
    "\n",
    "the following list of words has been correctly tagged by Viterbi_2 as compared to Viterbi_1\n",
    "\n",
    "* Sandinista: correctly tagged as NOUN\n",
    "* Eveready: correctly tagged as NOUN\n",
    "* *T*-252: correctly tagged as 'X'\n",
    "* drew: correctly tagged as VERB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate vanilla Viterbi and modified Viterbi on entire test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tagged_words = [tup[0] for sent in test_set for tup in sent]\n",
    "test_run_base = [tup for sent in test_set for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  2538.277092933655\n",
      "Modified Viterbi Algorithm Accuracy:  90.91440826671867\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  931.9766390323639\n",
      "Modified Viterbi Algorithm Accuracy:  95.43770715539091\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi_2(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n",
    "accuracy = len(check)/len(tagged_seq)\n",
    "print('Modified Viterbi Algorithm Accuracy: ',accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Test_sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_sent = text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_sent = sample_test_sent[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Android is a mobile operating system developed by Google.',\n",
       " 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.',\n",
       " \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\",\n",
       " 'Twitter is an online news and social networking service on which users post and interact with messages known as tweets.',\n",
       " 'Before entering politics, Donald Trump was a domineering businessman and a television personality.',\n",
       " 'The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.',\n",
       " 'This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.',\n",
       " 'Show me the cheapest round trips from Dallas to Atlanta']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of untagged words\n",
    "sample_test_words = [word for sent in sample_test_sent for word in sent.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  17.240669012069702\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq = Viterbi(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'DET'),\n",
       " ('Android', 'DET'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'DET'),\n",
       " ('worldwide', 'DET'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'DET'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'DET'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'DET'),\n",
       " ('Google', 'DET'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'DET'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'DET'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'DET'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'DET'),\n",
       " ('firehose.', 'DET'),\n",
       " ('Twitter', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'DET'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'DET'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'DET'),\n",
       " ('known', 'ADJ'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'DET'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'DET'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'DET'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'DET'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'DET'),\n",
       " ('FIFA', 'DET'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'DET'),\n",
       " ('FIFA', 'DET'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'DET'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'DET'),\n",
       " ('contested', 'DET'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'DET'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'DET'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'ADJ'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'DET'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'ADJ'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'DET'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that several words have been misclassified by vanilla Viterbi POS tagger, for example:\n",
    "\n",
    "* Android as NUM\n",
    "* Google as NUM\n",
    "* OS as NUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  17.494478702545166\n"
     ]
    }
   ],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "sample_tagged_seq = Viterbi_2(sample_test_words)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google.', 'NOUN'),\n",
       " ('Android', 'NOUN'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('best-selling', 'ADJ'),\n",
       " ('OS', 'NOUN'),\n",
       " ('worldwide', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('smartphones', 'VERB'),\n",
       " ('since', 'ADP'),\n",
       " ('2011', 'NUM'),\n",
       " ('and', 'CONJ'),\n",
       " ('on', 'ADP'),\n",
       " ('tablets', 'NOUN'),\n",
       " ('since', 'ADP'),\n",
       " ('2013.', 'NOUN'),\n",
       " ('Google', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('made', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('deal', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('2015', 'NUM'),\n",
       " ('that', 'ADP'),\n",
       " ('gave', 'VERB'),\n",
       " ('Google', 'NOUN'),\n",
       " ('access', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " (\"Twitter's\", 'NOUN'),\n",
       " ('firehose.', 'NOUN'),\n",
       " ('Twitter', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('an', 'DET'),\n",
       " ('online', 'NOUN'),\n",
       " ('news', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('social', 'ADJ'),\n",
       " ('networking', 'NOUN'),\n",
       " ('service', 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('which', 'DET'),\n",
       " ('users', 'NOUN'),\n",
       " ('post', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('interact', 'NOUN'),\n",
       " ('with', 'ADP'),\n",
       " ('messages', 'VERB'),\n",
       " ('known', 'VERB'),\n",
       " ('as', 'ADP'),\n",
       " ('tweets.', 'NOUN'),\n",
       " ('Before', 'ADP'),\n",
       " ('entering', 'VERB'),\n",
       " ('politics,', 'NOUN'),\n",
       " ('Donald', 'NOUN'),\n",
       " ('Trump', 'NOUN'),\n",
       " ('was', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('domineering', 'VERB'),\n",
       " ('businessman', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('a', 'DET'),\n",
       " ('television', 'NOUN'),\n",
       " ('personality.', 'NOUN'),\n",
       " ('The', 'DET'),\n",
       " ('2018', 'NUM'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('21st', 'NOUN'),\n",
       " ('FIFA', 'NOUN'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup,', 'NOUN'),\n",
       " ('an', 'DET'),\n",
       " ('international', 'ADJ'),\n",
       " ('football', 'NOUN'),\n",
       " ('tournament', 'NOUN'),\n",
       " ('contested', 'VERB'),\n",
       " ('once', 'ADV'),\n",
       " ('every', 'DET'),\n",
       " ('four', 'NUM'),\n",
       " ('years.', 'NOUN'),\n",
       " ('This', 'DET'),\n",
       " ('is', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('first', 'ADJ'),\n",
       " ('World', 'NOUN'),\n",
       " ('Cup', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('be', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Eastern', 'NOUN'),\n",
       " ('Europe', 'NOUN'),\n",
       " ('and', 'CONJ'),\n",
       " ('the', 'DET'),\n",
       " ('11th', 'ADJ'),\n",
       " ('time', 'NOUN'),\n",
       " ('that', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('has', 'VERB'),\n",
       " ('been', 'VERB'),\n",
       " ('held', 'VERB'),\n",
       " ('in', 'ADP'),\n",
       " ('Europe.', 'NOUN'),\n",
       " ('Show', 'NOUN'),\n",
       " ('me', 'PRON'),\n",
       " ('the', 'DET'),\n",
       " ('cheapest', 'ADJ'),\n",
       " ('round', 'NOUN'),\n",
       " ('trips', 'NOUN'),\n",
       " ('from', 'ADP'),\n",
       " ('Dallas', 'NOUN'),\n",
       " ('to', 'PRT'),\n",
       " ('Atlanta', 'NOUN')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_tagged_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these cases were correctly POS tagged by Viterbi_2:\n",
    "\n",
    "* Android as NOUN\n",
    "* Google as NOUN\n",
    "* OS as NOUN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of vanilla Viterbi Algorithm: 90.91%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of modified Viterbi Algorithm: 95.44%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cases were incorrectly tagged which got corrected by modified Viterbi Algorithm:\n",
    "\n",
    "* Contra:correctly tagged as NOUN\n",
    "* Honduras:correctly tagged as NOUN\n",
    "* complaining: correctly tagged as VERB\n",
    "* Bucking: correctly tagged as VERB\n",
    "* Sandinista: correctly tagged as NOUN\n",
    "* Eveready: correctly tagged as NOUN\n",
    "* \"*T*-252\": correctly tagged as 'X'\n",
    "* drew: correctly tagged as VERB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
